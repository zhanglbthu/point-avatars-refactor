train{
    # folder structure: exps_folder/subject/methodname/train_split/train/[checkpoints, saved conf]
    #                                                             /eval/test_split/step/image_folders
    exps_folder = /root/autodl-tmp/output/point-avatar/yufeng_1030 # location of experiments folder, use ln -s to link to data disk
    methodname = pointavatar
    dataset_class = datasets.real_dataset.FaceDataset
    learning_rate = 1.0e-4
    learning_rate_cam = 5.0e-4
    num_pixels = 2048
    max_points_training = 819200 # max number of points calculated during training (num_batch * num_points), reduce this if memory is limited.
    max_batch = 8
    upsample_freq = 5 # upsample is performed every 5 epochs, if number of points won't exceed point_cloud.max_points
    plot_freq = 1
    sched_milestones = [40, 60] # decay learning rate in these epochs
    sched_factor = 0.5
    GT_lbs_milestones = [10, 20, 30, 40] # decay flame regularization in these epcohs
    GT_lbs_factor = 0.5
    optimize_expression=True # optimize flame expressions
    optimize_camera=True # optimize camera and flame poses, this is important for alignment and numerical results...
}
loss{
    mask_weight = 1.0
    lbs_weight = 10.0
    eikonal_weight = 0.1
    sdf_consistency_weight =1.0
    vgg_feature_weight = 0.1
}
dataset{
    data_folder = /root/autodl-tmp/data/raw/point-avatar/datasets
    subject_name = yufeng
    json_name = flame_params.json
    use_mean_expression=True # canonical expression is set to the mean expression of the training dataset
    use_var_expression=True # used for blendshape regularization. Apply less regularization when expression variance is large.
    canonical_pose=0.4 # canonical pose is set to zero, except the jaw opening
    train{
        sub_dir = [MVI_1810, MVI_1814]
        img_res = [512, 512]
        subsample = 1
        load_images = True
    }
    test{
        sub_dir = [MVI_1812]
        img_res = [512, 512]
        subsample=  200
        load_images = True
    }
}
model{
    prune_thresh=0.5
    geometry_network
    {
        d_in = 3
        d_out = 1
        feature_vector_size = 3
        dims = [256, 256, 256, 256, 256, 256, 256, 256, 256]
        geometric_init = True
        bias = 0.6
        skip_in = [4]
        weight_norm = True
        multires = 6
    }
    rendering_network
    {
        d_in = 3
        feature_vector_size = 0
        d_out = 3
        dims = [64, 64]
        weight_norm = True
        multires_view = 0
        multires_pnts = 0
    }
    deformer_network
    {
        d_in = 3
        dims = [128, 128, 128, 128]
        weight_norm = True
        multires = 0
	    num_exp = 50
	    ghostbone = True
	    deform_c = True
    }
    point_cloud
    {
        n_init_points=400
        max_points=409600 # max number of points for the canonical model, reduce this if memory is limited.
    }
}
